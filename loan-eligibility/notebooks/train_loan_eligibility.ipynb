{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Eligibility Prediction Model Training\n",
    "\n",
    "This notebook demonstrates the training and evaluation of machine learning models for predicting loan eligibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, classification_report, confusion_matrix, roc_curve\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(n_samples=5000):\n",
    "    \"\"\"Generate synthetic loan application data\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    data = []\n",
    "    for _ in range(n_samples):\n",
    "        # Generate basic demographics\n",
    "        gender = np.random.choice(['Male', 'Female'])\n",
    "        married = np.random.choice(['Yes', 'No'])\n",
    "        dependents = np.random.randint(0, 4)\n",
    "        education = np.random.choice(['Graduate', 'Not Graduate'])\n",
    "        self_employed = np.random.choice(['Yes', 'No'])\n",
    "        \n",
    "        # Generate income and loan details\n",
    "        applicant_income = np.random.lognormal(10.5, 0.5)\n",
    "        coapplicant_income = np.random.lognormal(9.5, 0.8) if np.random.random() > 0.3 else 0\n",
    "        loan_amount = np.random.lognormal(12, 0.3)\n",
    "        loan_amount_term = np.random.choice([12, 24, 36, 60, 84, 120, 180, 240, 300, 360, 480])\n",
    "        \n",
    "        # Credit history (biased towards good credit)\n",
    "        credit_history = np.random.choice(['Yes', 'No'], p=[0.85, 0.15])\n",
    "        \n",
    "        # Property area\n",
    "        property_area = np.random.choice(['Urban', 'Semiurban', 'Rural'], p=[0.5, 0.3, 0.2])\n",
    "        \n",
    "        # Calculate eligibility based on multiple factors\n",
    "        approval_prob = 0.6\n",
    "        \n",
    "        # Income factors\n",
    "        total_income = applicant_income + coapplicant_income\n",
    "        income_to_loan_ratio = total_income / loan_amount\n",
    "        if income_to_loan_ratio > 0.3:\n",
    "            approval_prob += 0.2\n",
    "        elif income_to_loan_ratio > 0.2:\n",
    "            approval_prob += 0.1\n",
    "        else:\n",
    "            approval_prob -= 0.3\n",
    "        \n",
    "        # Credit history factor\n",
    "        if credit_history == 'Yes':\n",
    "            approval_prob += 0.3\n",
    "        else:\n",
    "            approval_prob -= 0.4\n",
    "        \n",
    "        # Education factor\n",
    "        if education == 'Graduate':\n",
    "            approval_prob += 0.1\n",
    "        else:\n",
    "            approval_prob -= 0.1\n",
    "        \n",
    "        # Final decision based on probability\n",
    "        approval_prob = max(0, min(1, approval_prob))\n",
    "        loan_status = 'Y' if np.random.random() < approval_prob else 'N'\n",
    "        \n",
    "        data.append({\n",
    "            'Gender': gender,\n",
    "            'Married': married,\n",
    "            'Dependents': dependents,\n",
    "            'Education': education,\n",
    "            'Self_Employed': self_employed,\n",
    "            'ApplicantIncome': applicant_income,\n",
    "            'CoapplicantIncome': coapplicant_income,\n",
    "            'LoanAmount': loan_amount,\n",
    "            'Loan_Amount_Term': loan_amount_term,\n",
    "            'Credit_History': credit_history,\n",
    "            'Property_Area': property_area,\n",
    "            'Loan_Status': loan_status\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Generate data\n",
    "print(\"Generating synthetic training data...\")\n",
    "df = generate_synthetic_data(5000)\n",
    "print(f\"Generated {len(df)} samples\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nTarget Distribution:\")\n",
    "print(df['Loan_Status'].value_counts())\n",
    "print(f\"Approval Rate: {df['Loan_Status'].value_counts()['Y'] / len(df) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "df['Loan_Status'].value_counts().plot(kind='bar', color=['skyblue', 'lightcoral'])\n",
    "plt.title('Loan Status Distribution')\n",
    "plt.xlabel('Loan Status')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "categorical_cols = ['Gender', 'Married', 'Education', 'Self_Employed', 'Credit_History', 'Property_Area']\n",
    "\n",
    "for i, col in enumerate(categorical_cols):\n",
    "    pd.crosstab(df[col], df['Loan_Status'], normalize='index').plot(kind='bar', ax=axes[i])\n",
    "    axes[i].set_title(f'Loan Approval Rate by {col}')\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Proportion')\n",
    "    axes[i].legend(['Rejected', 'Approved'])\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze numerical features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Income distribution\n",
    "df.boxplot(column='ApplicantIncome', by='Loan_Status', ax=axes[0,0])\n",
    "axes[0,0].set_title('Applicant Income by Loan Status')\n",
    "axes[0,0].set_xlabel('Loan Status')\n",
    "axes[0,0].set_ylabel('Applicant Income')\n",
    "\n",
    "# Loan amount distribution\n",
    "df.boxplot(column='LoanAmount', by='Loan_Status', ax=axes[0,1])\n",
    "axes[0,1].set_title('Loan Amount by Loan Status')\n",
    "axes[0,1].set_xlabel('Loan Status')\n",
    "axes[0,1].set_ylabel('Loan Amount')\n",
    "\n",
    "# Total income vs loan amount\n",
    "df['Total_Income'] = df['ApplicantIncome'] + df['CoapplicantIncome']\n",
    "approved = df[df['Loan_Status'] == 'Y']\n",
    "rejected = df[df['Loan_Status'] == 'N']\n",
    "\n",
    "axes[1,0].scatter(approved['Total_Income'], approved['LoanAmount'], alpha=0.6, label='Approved', color='green')\n",
    "axes[1,0].scatter(rejected['Total_Income'], rejected['LoanAmount'], alpha=0.6, label='Rejected', color='red')\n",
    "axes[1,0].set_xlabel('Total Income')\n",
    "axes[1,0].set_ylabel('Loan Amount')\n",
    "axes[1,0].set_title('Total Income vs Loan Amount')\n",
    "axes[1,0].legend()\n",
    "\n",
    "# Income to loan ratio\n",
    "df['Income_Loan_Ratio'] = df['Total_Income'] / df['LoanAmount']\n",
    "df.boxplot(column='Income_Loan_Ratio', by='Loan_Status', ax=axes[1,1])\n",
    "axes[1,1].set_title('Income-to-Loan Ratio by Loan Status')\n",
    "axes[1,1].set_xlabel('Loan Status')\n",
    "axes[1,1].set_ylabel('Income-to-Loan Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"Create additional features for better model performance\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Total income\n",
    "    df['Total_Income'] = df['ApplicantIncome'] + df['CoapplicantIncome']\n",
    "    \n",
    "    # Income to loan ratio\n",
    "    df['Income_Loan_Ratio'] = df['Total_Income'] / df['LoanAmount']\n",
    "    \n",
    "    # Per capita income (income per dependent)\n",
    "    df['Per_Capita_Income'] = df['Total_Income'] / (df['Dependents'] + 1)\n",
    "    \n",
    "    # Loan amount per month\n",
    "    df['Monthly_Loan_Amount'] = df['LoanAmount'] / df['Loan_Amount_Term']\n",
    "    \n",
    "    # Income stability indicator\n",
    "    df['Income_Stability'] = (df['Self_Employed'] == 'No').astype(int)\n",
    "    \n",
    "    # Family size\n",
    "    df['Family_Size'] = df['Dependents'] + (df['Married'] == 'Yes').astype(int) + 1\n",
    "    \n",
    "    # Credit history binary\n",
    "    df['Credit_History_Binary'] = (df['Credit_History'] == 'Yes').astype(int)\n",
    "    \n",
    "    # Property area encoded numerically\n",
    "    property_area_mapping = {'Rural': 0, 'Semiurban': 1, 'Urban': 2}\n",
    "    df['Property_Area_Numeric'] = df['Property_Area'].map(property_area_mapping)\n",
    "    \n",
    "    # Education level numeric\n",
    "    df['Education_Numeric'] = (df['Education'] == 'Graduate').astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "df_features = create_features(df)\n",
    "print(\"New features created:\")\n",
    "print(df_features.columns.tolist())\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess data for model training\"\"\"\n",
    "    # Separate features and target\n",
    "    X = df.drop(['Loan_Status'], axis=1)\n",
    "    y = df['Loan_Status'].map({'Y': 1, 'N': 0})\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    categorical_columns = ['Gender', 'Married', 'Education', 'Self_Employed', 'Credit_History', 'Property_Area']\n",
    "    \n",
    "    label_encoders = {}\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    return X.values, y.values, label_encoders\n",
    "\n",
    "# Preprocess data\n",
    "X, y, encoders = preprocess_data(df_features)\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {y.shape}\")\n",
    "print(f\"Features: {df_features.drop(['Loan_Status'], axis=1).columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1_score': f1_score(y_test, y_pred),\n",
    "        'auc_roc': roc_auc_score(y_test, y_pred_proba)\n",
    "    }\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'predictions': y_pred,\n",
    "        'probabilities': y_pred_proba,\n",
    "        'metrics': metrics\n",
    "    }\n",
    "    \n",
    "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"F1-Score: {metrics['f1_score']:.4f}\")\n",
    "    print(f\"AUC-ROC: {metrics['auc_roc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    model: results[model]['metrics'] \n",
    "    for model in results.keys()\n",
    "}).T\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "# Visualize comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "comparison_df.plot(kind='bar', ax=ax)\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve comparison\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for name, result in results.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, result['probabilities'])\n",
    "    auc = result['metrics']['auc_roc']\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names\n",
    "feature_names = df_features.drop(['Loan_Status'], axis=1).columns.tolist()\n",
    "\n",
    "# Feature importance for Gradient Boosting\n",
    "gb_model = results['Gradient Boosting']['model']\n",
    "feature_importance = gb_model.feature_importances_\n",
    "\n",
    "# Create importance dataframe\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "print(importance_df.head(10))\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = importance_df.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 15 Feature Importances (Gradient Boosting)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Confusion Matrix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrices for both models\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "for i, (name, result) in enumerate(results.items()):\n",
    "    cm = confusion_matrix(y_test, result['predictions'])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i])\n",
    "    axes[i].set_title(f'Confusion Matrix - {name}')\n",
    "    axes[i].set_xlabel('Predicted')\n",
    "    axes[i].set_ylabel('Actual')\n",
    "    axes[i].set_xticklabels(['Rejected', 'Approved'])\n",
    "    axes[i].set_yticklabels(['Rejected', 'Approved'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed classification reports\n",
    "for name, result in results.items():\n",
    "    print(f\"\\nClassification Report - {name}:\")\n",
    "    print(classification_report(y_test, result['predictions'], target_names=['Rejected', 'Approved']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Select best model based on F1-score\n",
    "best_model_name = max(results.keys(), key=lambda x: results[x]['metrics']['f1_score'])\n",
    "best_model = results[best_model_name]['model']\n",
    "\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "print(f\"F1-Score: {results[best_model_name]['metrics']['f1_score']:.4f}\")\n",
    "\n",
    "# Save model components\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save the complete model pipeline\n",
    "model_data = {\n",
    "    'model': best_model,\n",
    "    'scaler': scaler,\n",
    "    'label_encoders': encoders,\n",
    "    'feature_names': feature_names,\n",
    "    'metrics': results[best_model_name]['metrics']\n",
    "}\n",
    "\n",
    "joblib.dump(model_data, '../models/loan_eligibility_model.joblib')\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "# Also save individual components for the API\n",
    "joblib.dump(best_model, '../models/model.joblib')\n",
    "joblib.dump(scaler, '../models/scaler.joblib')\n",
    "joblib.dump(encoders, '../models/label_encoders.joblib')\n",
    "print(\"Individual components saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Test Model with Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with sample applicants\n",
    "test_applicants = [\n",
    "    {\n",
    "        'Gender': 'Male',\n",
    "        'Married': 'Yes',\n",
    "        'Dependents': 1,\n",
    "        'Education': 'Graduate',\n",
    "        'Self_Employed': 'No',\n",
    "        'ApplicantIncome': 5000,\n",
    "        'CoapplicantIncome': 3000,\n",
    "        'LoanAmount': 150000,\n",
    "        'Loan_Amount_Term': 360,\n",
    "        'Credit_History': 'Yes',\n",
    "        'Property_Area': 'Urban'\n",
    "    },\n",
    "    {\n",
    "        'Gender': 'Female',\n",
    "        'Married': 'No',\n",
    "        'Dependents': 3,\n",
    "        'Education': 'Not Graduate',\n",
    "        'Self_Employed': 'Yes',\n",
    "        'ApplicantIncome': 2000,\n",
    "        'CoapplicantIncome': 0,\n",
    "        'LoanAmount': 200000,\n",
    "        'Loan_Amount_Term': 240,\n",
    "        'Credit_History': 'No',\n",
    "        'Property_Area': 'Rural'\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, applicant in enumerate(test_applicants):\n",
    "    print(f\"\\nTest Applicant {i+1}:\")\n",
    "    print(f\"Income: ${applicant['ApplicantIncome'] + applicant['CoapplicantIncome']:,}\")\n",
    "    print(f\"Loan Amount: ${applicant['LoanAmount']:,}\")\n",
    "    print(f\"Credit History: {applicant['Credit_History']}\")\n",
    "    print(f\"Education: {applicant['Education']}\")\n",
    "    \n",
    "    # Preprocess and predict\n",
    "    df_test = pd.DataFrame([applicant])\n",
    "    df_test_features = create_features(df_test)\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    categorical_columns = ['Gender', 'Married', 'Education', 'Self_Employed', 'Credit_History', 'Property_Area']\n",
    "    for col in categorical_columns:\n",
    "        df_test_features[col] = encoders[col].transform(df_test_features[col])\n",
    "    \n",
    "    # Select features in correct order\n",
    "    X_test_sample = df_test_features[feature_names]\n",
    "    X_test_scaled_sample = scaler.transform(X_test_sample)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = best_model.predict(X_test_scaled_sample)[0]\n",
    "    probability = best_model.predict_proba(X_test_scaled_sample)[0, 1]\n",
    "    \n",
    "    print(f\"Prediction: {'Approved' if prediction == 1 else 'Rejected'}\")\n",
    "    print(f\"Probability: {probability:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Data Generation**: Created synthetic loan application data with realistic patterns\n",
    "2. **Exploratory Analysis**: Analyzed feature distributions and their relationship with loan approval\n",
    "3. **Feature Engineering**: Created additional features like income ratios and family size\n",
    "4. **Model Training**: Trained and compared Logistic Regression and Gradient Boosting models\n",
    "5. **Model Evaluation**: Used multiple metrics including accuracy, precision, recall, F1-score, and AUC-ROC\n",
    "6. **Feature Importance**: Identified the most important features for loan eligibility prediction\n",
    "7. **Model Saving**: Saved the best performing model for deployment\n",
    "\n",
    "The Gradient Boosting model showed superior performance and will be used in the API deployment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}