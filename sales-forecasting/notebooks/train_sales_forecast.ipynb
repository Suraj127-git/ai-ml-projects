{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sales Forecasting Model Training\n",
    "\n",
    "This notebook demonstrates training sales forecasting models using ARIMA, Prophet, and Linear Regression for time series forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from prophet import Prophet\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Sales Data\n",
    "\n",
    "Create realistic sales data with trends, seasonality, and noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sales_data(n_days=730, start_date='2022-01-01'):\n",
    "    \"\"\"Generate synthetic sales data with realistic patterns\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create date range\n",
    "    dates = pd.date_range(start=start_date, periods=n_days, freq='D')\n",
    "    \n",
    "    # Generate sales components\n",
    "    trend = np.linspace(1000, 2000, n_days)  # Upward trend\n",
    "    \n",
    "    # Weekly seasonality (higher on weekends)\n",
    "    weekly_seasonality = 200 * np.sin(2 * np.pi * np.arange(n_days) / 7)\n",
    "    \n",
    "    # Monthly seasonality\n",
    "    monthly_seasonality = 100 * np.sin(2 * np.pi * np.arange(n_days) / 30)\n",
    "    \n",
    "    # Yearly seasonality (holiday peaks)\n",
    "    yearly_seasonality = 300 * np.sin(2 * np.pi * np.arange(n_days) / 365)\n",
    "    \n",
    "    # Random noise\n",
    "    noise = np.random.normal(0, 50, n_days)\n",
    "    \n",
    "    # Combine components\n",
    "    sales = trend + weekly_seasonality + monthly_seasonality + yearly_seasonality + noise\n",
    "    sales = np.maximum(sales, 100)  # Ensure positive sales\n",
    "    \n",
    "    # Add promotional spikes\n",
    "    promo_days = np.random.choice(n_days, size=20, replace=False)\n",
    "    sales[promo_days] *= 1.5\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'sales': sales\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate data\n",
    "df = generate_sales_data(730)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"Sales range: ${df['sales'].min():.2f} to ${df['sales'].max():.2f}\")\n",
    "print(f\"Average daily sales: ${df['sales'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis\n",
    "\n",
    "Visualize sales patterns and trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Sales Statistics:\")\n",
    "print(df['sales'].describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# Set date as index for time series analysis\n",
    "df_ts = df.set_index('date')['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sales over time\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Daily sales\n",
    "axes[0, 0].plot(df['date'], df['sales'], alpha=0.7)\n",
    "axes[0, 0].set_title('Daily Sales Over Time')\n",
    "axes[0, 0].set_xlabel('Date')\n",
    "axes[0, 0].set_ylabel('Sales ($)')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Monthly aggregation\n",
    "monthly_sales = df.set_index('date').resample('M')['sales'].sum()\n",
    "axes[0, 1].plot(monthly_sales.index, monthly_sales.values, marker='o')\n",
    "axes[0, 1].set_title('Monthly Sales')\n",
    "axes[0, 1].set_xlabel('Date')\n",
    "axes[0, 1].set_ylabel('Sales ($)')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Weekly pattern\n",
    "df['day_of_week'] = df['date'].dt.dayofweek\n",
    "weekly_pattern = df.groupby('day_of_week')['sales'].mean()\n",
    "day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "axes[1, 0].bar(day_names, weekly_pattern.values)\n",
    "axes[1, 0].set_title('Average Sales by Day of Week')\n",
    "axes[1, 0].set_xlabel('Day of Week')\n",
    "axes[1, 0].set_ylabel('Average Sales ($)')\n",
    "\n",
    "# Distribution of daily sales\n",
    "axes[1, 1].hist(df['sales'], bins=30, alpha=0.7)\n",
    "axes[1, 1].set_title('Distribution of Daily Sales')\n",
    "axes[1, 1].set_xlabel('Sales ($)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Time Series Decomposition\n",
    "\n",
    "Decompose the time series into trend, seasonal, and residual components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform seasonal decomposition\n",
    "decomposition = seasonal_decompose(df_ts, model='additive', period=365)\n",
    "\n",
    "# Plot decomposition\n",
    "fig, axes = plt.subplots(4, 1, figsize=(15, 12))\n",
    "\n",
    "# Original series\n",
    "axes[0].plot(decomposition.observed)\n",
    "axes[0].set_title('Original Sales Data')\n",
    "axes[0].set_ylabel('Sales ($)')\n",
    "\n",
    "# Trend\n",
    "axes[1].plot(decomposition.trend)\n",
    "axes[1].set_title('Trend Component')\n",
    "axes[1].set_ylabel('Sales ($)')\n",
    "\n",
    "# Seasonal\n",
    "axes[2].plot(decomposition.seasonal)\n",
    "axes[2].set_title('Seasonal Component')\n",
    "axes[2].set_ylabel('Sales ($)')\n",
    "\n",
    "# Residual\n",
    "axes[3].plot(decomposition.resid)\n",
    "axes[3].set_title('Residual Component')\n",
    "axes[3].set_ylabel('Sales ($)')\n",
    "axes[3].set_xlabel('Date')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Time series decomposition completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ARIMA Model\n",
    "\n",
    "Train an ARIMA model for sales forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check stationarity\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def check_stationarity(timeseries):\n",
    "    \"\"\"Check if time series is stationary\"\"\"\n",
    "    result = adfuller(timeseries)\n",
    "    print('ADF Statistic:', result[0])\n",
    "    print('p-value:', result[1])\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f\"\\t{key}: {value}\")\n",
    "    \n",
    "    if result[1] <= 0.05:\n",
    "        print(\"Series is stationary\")\n",
    "    else:\n",
    "        print(\"Series is not stationary\")\n",
    "    \n",
    "    return result[1] <= 0.05\n",
    "\n",
    "# Check stationarity\n",
    "is_stationary = check_stationarity(df_ts)\n",
    "print(f\"\\nIs series stationary? {is_stationary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for training and testing\n",
    "train_size = int(len(df) * 0.8)\n",
    "train_data = df_ts[:train_size]\n",
    "test_data = df_ts[train_size:]\n",
    "\n",
    "print(f\"Training data: {len(train_data)} days\")\n",
    "print(f\"Test data: {len(test_data)} days\")\n",
    "print(f\"Train period: {train_data.index[0]} to {train_data.index[-1]}\")\n",
    "print(f\"Test period: {test_data.index[0]} to {test_data.index[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ARIMA model\n",
    "print(\"Training ARIMA model...\")\n",
    "arima_model = ARIMA(train_data, order=(1, 1, 1))\n",
    "arima_result = arima_model.fit()\n",
    "print(\"ARIMA model training completed!\")\n",
    "\n",
    "# Generate forecast\n",
    "forecast_steps = len(test_data)\n",
    "arima_forecast = arima_result.forecast(steps=forecast_steps)\n",
    "\n",
    "# Calculate metrics\n",
    "arima_mse = mean_squared_error(test_data, arima_forecast)\n",
    "arima_mae = mean_absolute_error(test_data, arima_forecast)\n",
    "arima_rmse = np.sqrt(arima_mse)\n",
    "\n",
    "print(f\"ARIMA RMSE: {arima_rmse:.2f}\")\n",
    "print(f\"ARIMA MAE: {arima_mae:.2f}\")\n",
    "print(f\"ARIMA MSE: {arima_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ARIMA results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_data.index, train_data.values, label='Training Data', color='blue')\n",
    "plt.plot(test_data.index, test_data.values, label='Actual Test Data', color='green')\n",
    "plt.plot(test_data.index, arima_forecast, label='ARIMA Forecast', color='red', linestyle='--')\n",
    "plt.title('ARIMA Model Forecast')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales ($)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prophet Model\n",
    "\n",
    "Train a Prophet model for sales forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Prophet\n",
    "prophet_train = train_data.reset_index()\n",
    "prophet_train.columns = ['ds', 'y']\n",
    "\n",
    "# Initialize and train Prophet\n",
    "print(\"Training Prophet model...\")\n",
    "prophet_model = Prophet(\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    daily_seasonality=False,\n",
    "    seasonality_mode='additive'\n",
    ")\n",
    "prophet_model.fit(prophet_train)\n",
    "print(\"Prophet model training completed!\")\n",
    "\n",
    "# Create future dataframe\n",
    "future = prophet_model.make_future_dataframe(periods=len(test_data))\n",
    "\n",
    "# Generate forecast\n",
    "prophet_forecast = prophet_model.predict(future)\n",
    "\n",
    "# Extract forecast for test period\n",
    "prophet_test_forecast = prophet_forecast.tail(len(test_data))['yhat'].values\n",
    "\n",
    "# Calculate metrics\n",
    "prophet_mse = mean_squared_error(test_data, prophet_test_forecast)\n",
    "prophet_mae = mean_absolute_error(test_data, prophet_test_forecast)\n",
    "prophet_rmse = np.sqrt(prophet_mse)\n",
    "\n",
    "print(f\"Prophet RMSE: {prophet_rmse:.2f}\")\n",
    "print(f\"Prophet MAE: {prophet_mae:.2f}\")\n",
    "print(f\"Prophet MSE: {prophet_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Prophet results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_data.index, train_data.values, label='Training Data', color='blue')\n",
    "plt.plot(test_data.index, test_data.values, label='Actual Test Data', color='green')\n",
    "plt.plot(test_data.index, prophet_test_forecast, label='Prophet Forecast', color='orange', linestyle='--')\n",
    "plt.title('Prophet Model Forecast')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales ($)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot Prophet components\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 10))\n",
    "\n",
    "# Trend\n",
    "axes[0].plot(prophet_forecast['ds'], prophet_forecast['trend'])\n",
    "axes[0].set_title('Trend Component')\n",
    "axes[0].set_ylabel('Sales ($)')\n",
    "\n",
    "# Yearly seasonality\n",
    "axes[1].plot(prophet_forecast['ds'], prophet_forecast['yearly'])\n",
    "axes[1].set_title('Yearly Seasonality')\n",
    "axes[1].set_ylabel('Sales ($)')\n",
    "\n",
    "# Weekly seasonality\n",
    "axes[2].plot(prophet_forecast['ds'], prophet_forecast['weekly'])\n",
    "axes[2].set_title('Weekly Seasonality')\n",
    "axes[2].set_ylabel('Sales ($)')\n",
    "axes[2].set_xlabel('Date')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Linear Regression Model\n",
    "\n",
    "Train a Linear Regression model with polynomial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for Linear Regression\n",
    "df_train = train_data.reset_index()\n",
    "df_train['day_of_week'] = df_train['date'].dt.dayofweek\n",
    "df_train['month'] = df_train['date'].dt.month\n",
    "df_train['year'] = df_train['date'].dt.year\n",
    "df_train['day_of_year'] = df_train['date'].dt.dayofyear\n",
    "\n",
    "# Create lag features\n",
    "df_train['sales_lag_1'] = df_train['sales'].shift(1)\n",
    "df_train['sales_lag_7'] = df_train['sales'].shift(7)\n",
    "df_train['sales_lag_30'] = df_train['sales'].shift(30)\n",
    "\n",
    "# Create rolling averages\n",
    "df_train['sales_ma_7'] = df_train['sales'].rolling(window=7).mean()\n",
    "df_train['sales_ma_30'] = df_train['sales'].rolling(window=30).mean()\n",
    "\n",
    "# Drop NaN values\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "# Prepare test data similarly\n",
    "df_test = test_data.reset_index()\n",
    "df_test['day_of_week'] = df_test['date'].dt.dayofweek\n",
    "df_test['month'] = df_test['date'].dt.month\n",
    "df_test['year'] = df_test['date'].dt.year\n",
    "df_test['day_of_year'] = df_test['date'].dt.dayofyear\n",
    "\n",
    "# Use last known values for test set\n",
    "last_train_row = df_train.iloc[-1]\n",
    "df_test['sales_lag_1'] = last_train_row['sales']\n",
    "df_test['sales_lag_7'] = last_train_row['sales']\n",
    "df_test['sales_lag_30'] = last_train_row['sales']\n",
    "df_test['sales_ma_7'] = last_train_row['sales_ma_7']\n",
    "df_test['sales_ma_30'] = last_train_row['sales_ma_30']\n",
    "\n",
    "print(\"Data preparation completed!\")\n",
    "print(f\"Training samples: {len(df_train)}\")\n",
    "print(f\"Test samples: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "feature_cols = [\n",
    "    'day_of_week', 'month', 'year', 'day_of_year',\n",
    "    'sales_lag_1', 'sales_lag_7', 'sales_lag_30',\n",
    "    'sales_ma_7', 'sales_ma_30'\n",
    "]\n",
    "\n",
    "X_train = df_train[feature_cols]\n",
    "y_train = df_train['sales']\n",
    "X_test = df_test[feature_cols]\n",
    "y_test = df_test['sales']\n",
    "\n",
    "# Create polynomial features\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "X_test_poly = poly_features.transform(X_test)\n",
    "\n",
    "# Train Linear Regression model\n",
    "print(\"Training Linear Regression model...\")\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_poly, y_train)\n",
    "print(\"Linear Regression model training completed!\")\n",
    "\n",
    "# Make predictions\n",
    "lr_predictions = lr_model.predict(X_test_poly)\n",
    "\n",
    "# Calculate metrics\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "lr_mae = mean_absolute_error(y_test, lr_predictions)\n",
    "lr_rmse = np.sqrt(lr_mse)\n",
    "\n",
    "print(f\"Linear Regression RMSE: {lr_rmse:.2f}\")\n",
    "print(f\"Linear Regression MAE: {lr_mae:.2f}\")\n",
    "print(f\"Linear Regression MSE: {lr_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Linear Regression results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_data.index, train_data.values, label='Training Data', color='blue')\n",
    "plt.plot(test_data.index, test_data.values, label='Actual Test Data', color='green')\n",
    "plt.plot(test_data.index, lr_predictions, label='Linear Regression Forecast', color='purple', linestyle='--')\n",
    "plt.title('Linear Regression Model Forecast')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales ($)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Comparison\n",
    "\n",
    "Compare the performance of all three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['ARIMA', 'Prophet', 'Linear Regression'],\n",
    "    'RMSE': [arima_rmse, prophet_rmse, lr_rmse],\n",
    "    'MAE': [arima_mae, prophet_mae, lr_mae],\n",
    "    'MSE': [arima_mse, prophet_mse, lr_mse]\n",
    "})\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(comparison_df.round(2))\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# RMSE comparison\n",
    "axes[0].bar(comparison_df['Model'], comparison_df['RMSE'], color=['red', 'orange', 'purple'])\n",
    "axes[0].set_title('RMSE Comparison')\n",
    "axes[0].set_ylabel('RMSE')\n",
    "\n",
    "# MAE comparison\n",
    "axes[1].bar(comparison_df['Model'], comparison_df['MAE'], color=['red', 'orange', 'purple'])\n",
    "axes[1].set_title('MAE Comparison')\n",
    "axes[1].set_ylabel('MAE')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find best model\n",
    "best_model = comparison_df.loc[comparison_df['RMSE'].idxmin(), 'Model']\n",
    "print(f\"\\nBest model based on RMSE: {best_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all forecasts together\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(train_data.index, train_data.values, label='Training Data', color='blue', alpha=0.7)\n",
    "plt.plot(test_data.index, test_data.values, label='Actual Test Data', color='black', linewidth=2)\n",
    "plt.plot(test_data.index, arima_forecast, label='ARIMA Forecast', color='red', linestyle='--')\n",
    "plt.plot(test_data.index, prophet_test_forecast, label='Prophet Forecast', color='orange', linestyle='--')\n",
    "plt.plot(test_data.index, lr_predictions, label='Linear Regression Forecast', color='purple', linestyle='--')\n",
    "plt.title('Sales Forecasting Models Comparison')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales ($)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Models\n",
    "\n",
    "Save the trained models for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save ARIMA model\n",
    "arima_data = {\n",
    "    'model': arima_result,\n",
    "    'model_type': 'arima'\n",
    "}\n",
    "joblib.dump(arima_data, '../sales_forecast_arima.pkl')\n",
    "print(\"ARIMA model saved!\")\n",
    "\n",
    "# Save Prophet model\n",
    "prophet_data = {\n",
    "    'model': prophet_model,\n",
    "    'training_data': prophet_train,\n",
    "    'model_type': 'prophet'\n",
    "}\n",
    "joblib.dump(prophet_data, '../sales_forecast_prophet.pkl')\n",
    "print(\"Prophet model saved!\")\n",
    "\n",
    "# Save Linear Regression model\n",
    "lr_data = {\n",
    "    'model': lr_model,\n",
    "    'scaler': poly_features,\n",
    "    'feature_names': feature_cols,\n",
    "    'model_type': 'linear_regression'\n",
    "}\n",
    "joblib.dump(lr_data, '../sales_forecast_linear.pkl')\n",
    "print(\"Linear Regression model saved!\")\n",
    "\n",
    "print(\"\\nAll models saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. Generation of synthetic sales data with realistic patterns\n",
    "2. Time series decomposition to understand components\n",
    "3. ARIMA model training and evaluation\n",
    "4. Prophet model training and component analysis\n",
    "5. Linear Regression with polynomial features\n",
    "6. Model comparison and performance evaluation\n",
    "7. Model saving for deployment\n",
    "\n",
    "The trained models can now be deployed as an API for sales forecasting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}